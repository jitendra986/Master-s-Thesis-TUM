{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "70-XsHkDGUKu",
    "outputId": "4a5f97ed-c7cc-44c4-fc13-65ae479147b4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in /home/eragroup/anaconda3/lib/python3.7/site-packages (1.13.1)\n",
      "Requirement already satisfied: torchvision in /home/eragroup/anaconda3/lib/python3.7/site-packages (0.14.1)\n",
      "Requirement already satisfied: matplotlib in /home/eragroup/anaconda3/lib/python3.7/site-packages (3.1.1)\n",
      "Requirement already satisfied: numpy in /home/eragroup/anaconda3/lib/python3.7/site-packages (1.21.6)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu11==11.7.99 in /home/eragroup/anaconda3/lib/python3.7/site-packages (from torch) (11.7.99)\n",
      "Requirement already satisfied: nvidia-cudnn-cu11==8.5.0.96 in /home/eragroup/anaconda3/lib/python3.7/site-packages (from torch) (8.5.0.96)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu11==11.7.99 in /home/eragroup/anaconda3/lib/python3.7/site-packages (from torch) (11.7.99)\n",
      "Requirement already satisfied: nvidia-cublas-cu11==11.10.3.66 in /home/eragroup/anaconda3/lib/python3.7/site-packages (from torch) (11.10.3.66)\n",
      "Requirement already satisfied: typing-extensions in /home/eragroup/anaconda3/lib/python3.7/site-packages (from torch) (4.2.0)\n",
      "Requirement already satisfied: wheel in /home/eragroup/anaconda3/lib/python3.7/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch) (0.33.6)\n",
      "Requirement already satisfied: setuptools in /home/eragroup/anaconda3/lib/python3.7/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch) (62.3.2)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /home/eragroup/anaconda3/lib/python3.7/site-packages (from torchvision) (6.2.0)\n",
      "Requirement already satisfied: requests in /home/eragroup/anaconda3/lib/python3.7/site-packages (from torchvision) (2.27.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /home/eragroup/anaconda3/lib/python3.7/site-packages (from matplotlib) (0.10.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /home/eragroup/anaconda3/lib/python3.7/site-packages (from matplotlib) (1.1.0)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /home/eragroup/anaconda3/lib/python3.7/site-packages (from matplotlib) (2.4.2)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in /home/eragroup/anaconda3/lib/python3.7/site-packages (from matplotlib) (2.8.2)\n",
      "Requirement already satisfied: six in /home/eragroup/anaconda3/lib/python3.7/site-packages (from cycler>=0.10->matplotlib) (1.12.0)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /home/eragroup/anaconda3/lib/python3.7/site-packages (from requests->torchvision) (2.0.12)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/eragroup/anaconda3/lib/python3.7/site-packages (from requests->torchvision) (2.8)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/eragroup/anaconda3/lib/python3.7/site-packages (from requests->torchvision) (1.24.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/eragroup/anaconda3/lib/python3.7/site-packages (from requests->torchvision) (2019.9.11)\n",
      "\u001b[33mWARNING: There was an error checking the latest version of pip.\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install torch torchvision matplotlib numpy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OmWTwJyIYWDo"
   },
   "source": [
    "### Import necessary Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "Yeksw_AMYVaV"
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import DataLoader, Dataset, Subset\n",
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "3wOjKm186Pth"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of available GPU:  1\n",
      "Available devices:\n",
      "- <torch.cuda.device object at 0x7f22d54878d0>\n"
     ]
    }
   ],
   "source": [
    "#from tensorflow.python.client import device_lib\n",
    "#device_lib.list_local_devices()\n",
    "\n",
    "# Get the available devices\n",
    "devices = [torch.cuda.device(i) for i in range(torch.cuda.device_count())]\n",
    "print('number of available GPU: ',torch.cuda.device_count())  # Should print the number of visible devices\n",
    "\n",
    "# Print the available devices\n",
    "print(\"Available devices:\")\n",
    "for device in devices:\n",
    "    print(f\"- {device}\")\n",
    "device = torch.device(\"cuda:0\")  # Use the first GPU\n",
    "\n",
    "# Print the current device\n",
    "#print(f\"Current device: {torch.cuda.current_device()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8014462976, 8512602112)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.mem_get_info(device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mon Jul  1 00:40:58 2024       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 470.182.03   Driver Version: 470.182.03   CUDA Version: 11.4     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  Quadro P4000        Off  | 00000000:65:00.0  On |                  N/A |\n",
      "| 48%   44C    P0    29W / 105W |    475MiB /  8118MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|    0   N/A  N/A      1168      G   ...roup/anaconda3/bin/python        1MiB |\n",
      "|    0   N/A  N/A      1240      G   /usr/lib/xorg/Xorg                 12MiB |\n",
      "|    0   N/A  N/A      1754      G   kwin_x11                          104MiB |\n",
      "|    0   N/A  N/A      1761      G   /usr/bin/krunner                    1MiB |\n",
      "|    0   N/A  N/A      1816      G   /usr/lib/firefox/firefox            2MiB |\n",
      "|    0   N/A  N/A      2273      G   ...s/spyder-5.5.1/bin/python       19MiB |\n",
      "|    0   N/A  N/A     11479      C   ...roup/anaconda3/bin/python       77MiB |\n",
      "|    0   N/A  N/A     15451      G   /usr/lib/xorg/Xorg                154MiB |\n",
      "|    0   N/A  N/A     15724      G   kwin_x11                            5MiB |\n",
      "|    0   N/A  N/A     15732      G   /usr/bin/krunner                   19MiB |\n",
      "|    0   N/A  N/A     15734      G   /usr/bin/plasmashell               54MiB |\n",
      "|    0   N/A  N/A     18871      G   ...mviewer/tv_bin/TeamViewer        6MiB |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "4BsYPkY7gYGx"
   },
   "outputs": [],
   "source": [
    "# Multiclass classification\n",
    "#Predict if an asset will fail within two different intervals related to the two different decisions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2iklamKYlNjh"
   },
   "source": [
    "\n",
    "`os`: This module provides functions for interacting with the operating system. It's commonly used for tasks such as file manipulation and directory operations.<br>\n",
    "`sklearn.preprocessing`: This module from scikit-learn provides functions for preprocessing data, such as scaling, normalization, and encoding categorical variables.<br>\n",
    "`sklearn.metrics`: This module contains functions for evaluating model performance, such as computing confusion matrices, recall scores, and precision scores.<br>\n",
    "`multiclass_model_w1_30.h5`:The .h5 extension indicates that the model will be saved in the Hierarchical Data Format version 5 (HDF5) format, which is commonly used for storing large numerical datasets. The model will be saved with the filename **multiclass_model_w1_30.h5.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "QfpzPSgG-If3"
   },
   "outputs": [],
   "source": [
    "# Setting seed for reproducibility\n",
    "np.random.seed(1234)\n",
    "PYTHONHASHSEED = 0\n",
    "\n",
    "from sklearn import preprocessing\n",
    "from sklearn.metrics import confusion_matrix, recall_score, precision_score\n",
    "#from tensorflow.keras.models import Sequential,load_model\n",
    "#from tensorflow.keras.layers import Dense, Dropout, LSTM\n",
    "\n",
    "# define path to save model\n",
    "model_path = 'multiclass_model_w1_30.h5'# This file then contains the already trained network, so that you don't have to retrain every time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EilFg--x-ety"
   },
   "source": [
    "## Data Ingestion\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "JjbfnUZGgc3C"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((12138, 50, 25), (12138, 3), (1742, 50, 25), (1742, 3))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read training data - It is the aircraft engine run-to-failure data.\n",
    "from data_preprocessor import DataPreprocessor\n",
    "\n",
    "# Initialize the preprocessor with the path to your training data file\n",
    "preprocessor = DataPreprocessor('PM_train.txt')\n",
    "\n",
    "# Preprocess the data\n",
    "seq_array, dummy_label_array, seq_array_validation, dummy_label_array_validation = preprocessor.preprocess()\n",
    "seq_array.shape, dummy_label_array.shape, seq_array_validation.shape, dummy_label_array_validation.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XrpsNnInsevi"
   },
   "source": [
    "`train_df.sort_values(['id','cycle'])`: This line sorts the DataFrame **train_df** first by the 'id' column and then by the 'cycle' column. It ensures that the data is ordered by engine ID and cycle number, which may be necessary for certain analyses or modeling tasks. The sorted DataFrame is then assigned back to the variable **train_df**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QEpD7amS-lpu"
   },
   "source": [
    "## Data Preprocessing\n",
    "data preprocessing step, particularly for labeling the data for training purposes. Let's break down what each part of the code does:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "O5-_dxq60Nf4"
   },
   "source": [
    ">`Data Labeling`: This part calculates the Remaining Useful Life (RUL) or Time to Failure for each engine by finding the maximum cycle number (cycle) for each engine ID (id). The result is stored in a DataFrame rul with columns 'id' and 'max'.<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_ZubPMTD0T9z"
   },
   "source": [
    ">`Merge RUL with Training Data`:the RUL information is merged back into the original training DataFrame **train_df** based on the engine ID. This allows each row in train_df to have the corresponding maximum cycle number as well.<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "d-eouxGv0gpG"
   },
   "source": [
    ">`Calculate RUL`: This line calculates the RUL by subtracting the current cycle number ('cycle') from the maximum cycle number ('max') for each engine. This represents how many more cycles the engine is expected to operate before failure.<br>\n",
    ">`Drop Unnecessary Columns`: After calculating RUL, the 'max' column, which was used temporarily to calculate RUL, is dropped from the DataFrame as it's no longer needed.<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oBFd2pLr0odt"
   },
   "source": [
    "> `Labeling for Classification`: This part assigns labels to each data point based on the calculated RUL. It defines thresholds `w1` and `w0`, and assigns:\n",
    ">> * Label 1 ('label1') as 1 if RUL is less than or equal to 'w1', and 0 otherwise.\n",
    ">> * Label2 ('label2') as 1 if RUL is less than or equal to 'w1', 2 if RUL is less than or equal to 'w0', and 0 otherwise."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "F_8MNc2Z6Ptu"
   },
   "source": [
    " Now I want to separate the train_df set into a training/validation/test set. I will use 80% training sets for the training and 10% training sets as validation sets for hyperparameter tuning and the remaining 10% as test set for the PdM policy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "13rqadVW6Ptv"
   },
   "source": [
    "I separate into training and validation and test set before any data scaling is performed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oPP7siRw6Ptx"
   },
   "source": [
    "Perform the min max scaling on the training data and validation dataset\n",
    "use min_max_scaler.fit_transform()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VYkFz5FqQplh"
   },
   "source": [
    ">`Create a copy of the cycle column`: This line creates a new column named 'cycle_norm' in the train_df DataFrame and initializes it with the values from the original 'cycle' column. This column will be normalized later.<br>\n",
    "> `Select columns for normalization`: This line selects all columns from **train_df** except 'id', 'cycle', 'RUL', 'label1', and 'label2'. These columns are the ones that will undergo normalization.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "62AHbVv4RgN-"
   },
   "source": [
    "> `Initialize MinMaxScaler`: This line initializes a MinMaxScaler object from the scikit-learn preprocessing module. This scaler will be used to perform Min-Max normalization.<br>\n",
    "> `Perform Min-Max normalization`: This line applies Min-Max normalization to the selected columns (`cols_normalize`) of the `train_df` DataFrame.<br>\n",
    "> `min_max_scaler.fit_transform(train_df[cols_normalize])` computes the Min-Max normalization for the selected columns.<br>\n",
    "> The resulting normalized values are stored in a new DataFrame called `norm_train_df`, with the same index as `train_df`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MBEf7s4DS3jR"
   },
   "source": [
    "> `Join normalized DataFrame with the original DataFrame`: This line joins the normalized DataFrame (`norm_train_df`) with the original DataFrame (`train_df`) excluding the columns that were normalized.<br>\n",
    "> The resulting DataFrame `join_df` contains both the normalized columns and the original columns that were not normalized.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dF2-ITehT1_P"
   },
   "source": [
    "`Reorder columns`:\n",
    "> * This line reorders the columns of `join_df` to match the original order of columns in `train_df`.\n",
    "> * The reordered DataFrame is then assigned back to `train_df`, effectively replacing the original DataFrame with the normalized version.\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "57FSFDb4-r3d"
   },
   "source": [
    "## Vanilla Transformer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When you use `sequence_cols.extend(sensor_cols)`, it adds each element of `sensor_cols` to the end of `sequence_cols`.<br>\n",
    "After this operation, `sequence_cols` will contain 25 elements: 4 operational settings followed by 21 sensor readings.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YEV0vj7AkJOl"
   },
   "source": [
    "## generate sequences for each engine\n",
    "> * This creates a generator expression that iterates over unique engine IDs in the training data.<br>\n",
    "> * For each engine, it generates sequences using the `gen_sequence` function defined earlier.<br>\n",
    "> * Each sequence is a list of sensor data, and multiple sequences are generated for each engine.<br>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "z_Fc99j1rPQa"
   },
   "source": [
    "> * This concatenates all the generated sequences into a single numpy array.\n",
    "> * It converts the array to `float32` data type.\n",
    "> * The resulting `seq_array` contains the sequences of sensor data, with shape `(num_sequences, sequence_length, num_features)`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1718782949253,
     "user": {
      "displayName": "jitendra tiwari",
      "userId": "04882265798590373880"
     },
     "user_tz": -120
    },
    "id": "An8AqEX_6Pty"
   },
   "outputs": [],
   "source": [
    "# we always take the measurements of the last 50 cycles as input!\n",
    "# Every sequence is reduced by a length of 50 (=sequence_length). We have 80 training sets, 80*50 = 4000 \"less\" inputs\n",
    "# train_df.shape = (16138, 30)\n",
    "# seq_array.shape = (12138, 50, 25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Chu8ocOhxkaf"
   },
   "source": [
    "`Function Signature:` This function efficiently generates labels for each sequence of sensor data. It ensures that the labels are correctly aligned with the sequences and handles the special case where the first sequence uses the last label as its target.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "> This function takes three arguments:\n",
    ">> * `id_df:` DataFrame containing data for a specific engine (id).<br>\n",
    ">> * `seq_length`: Length of the sequence window.<br>\n",
    ">> * `label`: List of column names representing the labels.\n",
    "\n",
    "`Data Preparation:`\n",
    "> * `data_matrix = id_df[label].values:`\n",
    ">> * This line extracts the columns specified by label from the DataFrame id_df and converts them to a numpy array.<br>\n",
    ">> * It selects only the relevant label(s) needed for generating sequences.<br>\n",
    "\n",
    "`Label Generation:`\n",
    "> * `num_elements:`This line calculates the number of rows (elements) in the data matrix, which corresponds to the number of labels.<br>\n",
    "> * `return data_matrix[seq_length:num_elements, :]:`\n",
    ">> * This line returns the labels associated with each sequence.<br>\n",
    ">> * It removes the first `seq_length` labels because, for each engine (`id`), the first sequence of size `seq_length` uses the last label as its target. The previous labels are discarded.<br>\n",
    ">> * All subsequent sequences for the same engine (`id`) will have one label associated with them step by step.<br>\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When modeling multi-class classification problems using neural networks,<br>\n",
    "it is good practice to reshape the output attribute from a vector that contains values for each class value to be<br>\n",
    "a matrix with a boolean for each class value and whether or not a given instance has that class value or not.<br>\n",
    "This is called one hot encoding or creating dummy variables from a categorical variable.<br>\n",
    "\n",
    "from tensorflow.keras.utils import to_categorical<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6qBrRZdYZiHb"
   },
   "source": [
    "`to_categorical` is a utility function in Keras that converts class vectors (integers) to binary class matrices.<br>\n",
    "`dummy_label_array = to_categorical(label_array):`This line applies one-hot encoding to the `label_array`.<br>\n",
    "`label_array` contains the labels associated with each sequence, where each label represents a class or category.<br>\n",
    "> * One-hot encoding converts these integer labels into binary vectors, where each vector has a length equal to the number of classes and contains a 1 in the position corresponding to the class and 0s elsewhere.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 9,
     "status": "ok",
     "timestamp": 1718782965252,
     "user": {
      "displayName": "jitendra tiwari",
      "userId": "04882265798590373880"
     },
     "user_tz": -120
    },
    "id": "XnwyiGj06Pt0",
    "outputId": "b319666d-4293-4940-843e-a3bce535053c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       ...,\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dummy_label_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 10,
     "status": "ok",
     "timestamp": 1718782966954,
     "user": {
      "displayName": "jitendra tiwari",
      "userId": "04882265798590373880"
     },
     "user_tz": -120
    },
    "id": "qbAJg5KqY-In",
    "outputId": "22d56de8-00e6-4671-b0cd-d47c0e24276c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       ...,\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dummy_label_array_validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1742, 3)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dummy_label_array_validation.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 9,
     "status": "ok",
     "timestamp": 1718782969359,
     "user": {
      "displayName": "jitendra tiwari",
      "userId": "04882265798590373880"
     },
     "user_tz": -120
    },
    "id": "M40CNdn7krRw",
    "outputId": "9df2380d-c7b1-43df-cb41-ec51fb81c98f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12138, 3)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dummy_label_array.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 9,
     "status": "ok",
     "timestamp": 1718782971301,
     "user": {
      "displayName": "jitendra tiwari",
      "userId": "04882265798590373880"
     },
     "user_tz": -120
    },
    "id": "dWhWIVl56Pt1",
    "outputId": "a9a57d55-f589-4306-954f-0d36aed732c2",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25, 3)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb_features = seq_array.shape[2]\n",
    "nb_out      = dummy_label_array.shape[1]\n",
    "nb_features, nb_out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "s0h3i_FJg7pJ"
   },
   "source": [
    "`Extracting Feature and Output Dimensions:`\n",
    "> `nb_features:`Determines the number of features in the input sequence data.<br>\n",
    "> `nb_out:`Determines the number of output classes. It's extracted from the shape of the label array.<br>\n",
    "\n",
    "`Defining the Model Architecture:` describe in the code below.\n",
    "`Compiling the Model:` `model.compile(...)` Here, `categorical_crossentropy` is used as the loss function for multi-class classification.\n",
    "\n",
    "`Model Summary:`Prints a summary of the model architecture, including the layers and their parameters.\n",
    "\n",
    "`Training the Model:` `model.fit(...):` Trains the model on the training data. It specifies the input data (`seq_array`) and the corresponding labels (`dummy_label_array`). Other parameters include the number of epochs, batch size, validation split, verbosity, and callbacks.<br>\n",
    "\n",
    "\n",
    "`history.history.keys():` After training, this prints the keys of the history object, which contains information about training and validation metrics over each epoch.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WOmuAimTDi5p"
   },
   "source": [
    "### Define the Dataset:\n",
    "Create a custom dataset class to handle your multivariate time series data with labels.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2500,
     "status": "ok",
     "timestamp": 1718791179567,
     "user": {
      "displayName": "jitendra tiwari",
      "userId": "04882265798590373880"
     },
     "user_tz": -120
    },
    "id": "C5EsCykBKvsT",
    "outputId": "ebb36239-3bab-4478-9e21-ea72b12ac2ba"
   },
   "outputs": [],
   "source": [
    "#from google.colab import drive\n",
    "#drive.mount('/content/drive')\n",
    "\n",
    "#import os\n",
    "#os.chdir('/content/drive/MyDrive/Colab Notebooks/LSTM_Antonis')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "V6baBqY-Oli3"
   },
   "source": [
    "`Shuffling Batches:` By setting `shuffle=True` in the `DataLoader` for the training set, you ensure that the order of batches is shuffled each epoch. This maintains the temporal structure within each batch while still introducing variability in the order in which batches are processed.<br>\n",
    "\n",
    "`DataLoader for Validation:` Ensure `shuffle=False` for the validation set to maintain the sequence order during validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "executionInfo": {
     "elapsed": 406,
     "status": "ok",
     "timestamp": 1718791182861,
     "user": {
      "displayName": "jitendra tiwari",
      "userId": "04882265798590373880"
     },
     "user_tz": -120
    },
    "id": "8SbqCLucDib9"
   },
   "outputs": [],
   "source": [
    "# Import custom classes\n",
    "import torch\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "from dataset import MultivariateTimeSeriesDataset\n",
    "from model import TransformerTimeSeriesModel\n",
    "\n",
    "# Load parameters from JSON file\n",
    "with open('params.json', 'r') as f:\n",
    "    params = json.load(f)\n",
    "\n",
    "# Example usage with seq_array and dummy_var\n",
    "#seq_array --> (12138, 50, 25)  # use this as your actual data\n",
    "#dummy_var --->  (12138, 3) # use this as your actual dummy variable (3 classes)\n",
    "\n",
    "#train_indices, val_indices = train_test_split(np.arange(len(seq_array)), test_size=0.05, random_state=42)\n",
    "# Check for data leakage\n",
    "#assert len(set(train_indices).intersection(set(val_indices))) == 0, \"Data leakage detected between training and validation sets\"\n",
    "\n",
    "train_dataset = MultivariateTimeSeriesDataset(seq_array, dummy_label_array, params['seq_length'])\n",
    "val_dataset = MultivariateTimeSeriesDataset(seq_array_validation, dummy_label_array_validation, params['seq_length'])\n",
    "\n",
    "# Shuffle batches by setting shuffle=True in DataLoader\n",
    "train_loader = DataLoader(train_dataset, batch_size=params['batch_size'], shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=params['batch_size'], shuffle=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jQmBGIESY4qE"
   },
   "source": [
    "### Define the Transformer Model:\n",
    "Implement the vanilla Transformer architecture, ensuring it takes the dummy variable as an input.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 469,
     "status": "ok",
     "timestamp": 1718791187021,
     "user": {
      "displayName": "jitendra tiwari",
      "userId": "04882265798590373880"
     },
     "user_tz": -120
    },
    "id": "X9YmurfGDthf",
    "outputId": "10bb7a47-503c-4aaf-ef0d-80167896e2f3"
   },
   "outputs": [],
   "source": [
    "# Instantiate the model using parameters from the JSON file\n",
    "model = TransformerTimeSeriesModel(\n",
    "    input_dim=params['input_dim'],\n",
    "    model_dim=params['model_dim'],\n",
    "    num_heads=params['num_heads'],\n",
    "    num_layers=params['num_layers'],\n",
    "    seq_length=params['seq_length'],\n",
    "    num_classes=params['num_classes'],\n",
    "    dropout_rate=params['dropout_rate']\n",
    ").to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TransformerTimeSeriesModel(\n",
       "  (input_embedding): Linear(in_features=25, out_features=16, bias=True)\n",
       "  (transformer): Transformer(\n",
       "    (encoder): TransformerEncoder(\n",
       "      (layers): ModuleList(\n",
       "        (0): TransformerEncoderLayer(\n",
       "          (self_attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=16, out_features=16, bias=True)\n",
       "          )\n",
       "          (linear1): Linear(in_features=16, out_features=64, bias=True)\n",
       "          (dropout): Dropout(p=0.2868566573951219, inplace=False)\n",
       "          (linear2): Linear(in_features=64, out_features=16, bias=True)\n",
       "          (norm1): LayerNorm((16,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm2): LayerNorm((16,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout1): Dropout(p=0.2868566573951219, inplace=False)\n",
       "          (dropout2): Dropout(p=0.2868566573951219, inplace=False)\n",
       "        )\n",
       "        (1): TransformerEncoderLayer(\n",
       "          (self_attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=16, out_features=16, bias=True)\n",
       "          )\n",
       "          (linear1): Linear(in_features=16, out_features=64, bias=True)\n",
       "          (dropout): Dropout(p=0.2868566573951219, inplace=False)\n",
       "          (linear2): Linear(in_features=64, out_features=16, bias=True)\n",
       "          (norm1): LayerNorm((16,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm2): LayerNorm((16,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout1): Dropout(p=0.2868566573951219, inplace=False)\n",
       "          (dropout2): Dropout(p=0.2868566573951219, inplace=False)\n",
       "        )\n",
       "        (2): TransformerEncoderLayer(\n",
       "          (self_attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=16, out_features=16, bias=True)\n",
       "          )\n",
       "          (linear1): Linear(in_features=16, out_features=64, bias=True)\n",
       "          (dropout): Dropout(p=0.2868566573951219, inplace=False)\n",
       "          (linear2): Linear(in_features=64, out_features=16, bias=True)\n",
       "          (norm1): LayerNorm((16,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm2): LayerNorm((16,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout1): Dropout(p=0.2868566573951219, inplace=False)\n",
       "          (dropout2): Dropout(p=0.2868566573951219, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (norm): LayerNorm((16,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (decoder): TransformerDecoder(\n",
       "      (layers): ModuleList(\n",
       "        (0): TransformerDecoderLayer(\n",
       "          (self_attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=16, out_features=16, bias=True)\n",
       "          )\n",
       "          (multihead_attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=16, out_features=16, bias=True)\n",
       "          )\n",
       "          (linear1): Linear(in_features=16, out_features=64, bias=True)\n",
       "          (dropout): Dropout(p=0.2868566573951219, inplace=False)\n",
       "          (linear2): Linear(in_features=64, out_features=16, bias=True)\n",
       "          (norm1): LayerNorm((16,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm2): LayerNorm((16,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm3): LayerNorm((16,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout1): Dropout(p=0.2868566573951219, inplace=False)\n",
       "          (dropout2): Dropout(p=0.2868566573951219, inplace=False)\n",
       "          (dropout3): Dropout(p=0.2868566573951219, inplace=False)\n",
       "        )\n",
       "        (1): TransformerDecoderLayer(\n",
       "          (self_attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=16, out_features=16, bias=True)\n",
       "          )\n",
       "          (multihead_attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=16, out_features=16, bias=True)\n",
       "          )\n",
       "          (linear1): Linear(in_features=16, out_features=64, bias=True)\n",
       "          (dropout): Dropout(p=0.2868566573951219, inplace=False)\n",
       "          (linear2): Linear(in_features=64, out_features=16, bias=True)\n",
       "          (norm1): LayerNorm((16,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm2): LayerNorm((16,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm3): LayerNorm((16,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout1): Dropout(p=0.2868566573951219, inplace=False)\n",
       "          (dropout2): Dropout(p=0.2868566573951219, inplace=False)\n",
       "          (dropout3): Dropout(p=0.2868566573951219, inplace=False)\n",
       "        )\n",
       "        (2): TransformerDecoderLayer(\n",
       "          (self_attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=16, out_features=16, bias=True)\n",
       "          )\n",
       "          (multihead_attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=16, out_features=16, bias=True)\n",
       "          )\n",
       "          (linear1): Linear(in_features=16, out_features=64, bias=True)\n",
       "          (dropout): Dropout(p=0.2868566573951219, inplace=False)\n",
       "          (linear2): Linear(in_features=64, out_features=16, bias=True)\n",
       "          (norm1): LayerNorm((16,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm2): LayerNorm((16,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm3): LayerNorm((16,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout1): Dropout(p=0.2868566573951219, inplace=False)\n",
       "          (dropout2): Dropout(p=0.2868566573951219, inplace=False)\n",
       "          (dropout3): Dropout(p=0.2868566573951219, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (norm): LayerNorm((16,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "  )\n",
       "  (classification_output): Linear(in_features=16, out_features=3, bias=True)\n",
       "  (dropout): Dropout(p=0.2868566573951219, inplace=False)\n",
       ")"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24371"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(p.numel() for p in model.parameters() if p.requires_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Expand val_dummy to match the sequence length of val_data\n",
    "#val_dummy_expanded = np.repeat(dummy_label_array_validation[:, np.newaxis, :], params['seq_length'], axis=1)\n",
    "\n",
    "#print(f'val_dummy_expanded shape: {val_dummy_expanded.shape}')  # Should print: val_dummy_expanded shape: (1742, 50, 3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3035"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_dim': 25,\n",
       " 'model_dim': 16,\n",
       " 'num_heads': 2,\n",
       " 'num_layers': 3,\n",
       " 'seq_length': 50,\n",
       " 'num_classes': 3,\n",
       " 'dropout_rate': 0.2868566573951219,\n",
       " 'learning_rate': 0.008660297626080152,\n",
       " 'batch_size': 4,\n",
       " 'num_epochs': 5,\n",
       " 'weight_decay': 0.0008257506721260046,\n",
       " 'patience': 5}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nfor batch in train_loader:\\n    print(batch)\\n'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "for batch in train_loader:\n",
    "    print(batch)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FV8tK1SNV2e-"
   },
   "source": [
    "### Training the model\n",
    "\n",
    "Define the training loop with the loss function and optimizer, and include the dummy variable in the forward pass.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 191
    },
    "executionInfo": {
     "elapsed": 887,
     "status": "ok",
     "timestamp": 1718791191993,
     "user": {
      "displayName": "jitendra tiwari",
      "userId": "04882265798590373880"
     },
     "user_tz": -120
    },
    "id": "SSBHKI-XXoFQ",
    "outputId": "60d5ce9d-4710-40aa-e2bc-29909fe8e5d4"
   },
   "outputs": [],
   "source": [
    "#reconstruction_criterion = nn.MSELoss()\n",
    "torch.optim \n",
    "classification_criterion = nn.CrossEntropyLoss()\n",
    "#optimizer = torch.optim.Adam(model.parameters(), lr=params['learning_rate'])\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=params['learning_rate'], weight_decay=params['weight_decay'])\n",
    "#scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', patience=params['patience'])\n",
    "\n",
    "# Learning rate scheduler with ReduceLROnPlateau for early stopping\n",
    "#scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', patience=params['patience'], verbose=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#os.environ['PYTORCH_CUDA_ALLOC_CONF'] = 'max_split_size_mb:32'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "background_save": true,
     "base_uri": "https://localhost:8080/"
    },
    "id": "i--r71JmV1LD"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5, Training Loss: 0.6489263273714205\n",
      "Epoch 1/5, Validation Loss: 0.5920122267182814\n",
      "Epoch 2/5, Training Loss: 0.6407286782879413\n",
      "Epoch 2/5, Validation Loss: 0.5964255237251247\n",
      "Epoch 3/5, Training Loss: 0.6413671656240152\n",
      "Epoch 3/5, Validation Loss: 0.5887445245587498\n",
      "Epoch 4/5, Training Loss: 0.6409338089838452\n",
      "Epoch 4/5, Validation Loss: 0.5924541114940556\n",
      "Epoch 5/5, Training Loss: 0.6413560569654579\n",
      "Epoch 5/5, Validation Loss: 0.5876542239560993\n"
     ]
    }
   ],
   "source": [
    "# Instantiate early stopping\n",
    "#early_stopping = EarlyStopping(patience=params['patience'], verbose=True)\n",
    "\n",
    "# Set up model, loss function, and optimizer\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model_params = {k: v for k, v in params.items() if k not in ['learning_rate', 'batch_size', 'num_epochs', 'weight_decay','patience']}\n",
    "model = TransformerTimeSeriesModel(**model_params).to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=params['learning_rate'], weight_decay=params['weight_decay'])\n",
    "\n",
    "\n",
    "num_epochs = params['num_epochs']\n",
    "train_losses = []\n",
    "val_losses  = []\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    epoch_loss = 0\n",
    "    for batch in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        inputs, dummies = batch\n",
    "        inputs = inputs.float().to(device)\n",
    "        dummies = dummies.float().to(device)\n",
    "\n",
    "        outputs_class = model(inputs)\n",
    "\n",
    "        outputs_reshaped = outputs_class.view(-1, params['num_classes'])\n",
    "        dummies_reshaped = dummies.view(-1, params['num_classes'])\n",
    "        loss = criterion(outputs_reshaped, dummies_reshaped.argmax(dim=1))\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        epoch_loss += loss.item()\n",
    "\n",
    "    average_epoch_loss = epoch_loss / len(train_loader)\n",
    "    train_losses.append(average_epoch_loss)\n",
    "    print(f'Epoch {epoch+1}/{num_epochs}, Training Loss: {average_epoch_loss}')\n",
    "\n",
    "    # Validation\n",
    "    model.eval()\n",
    "    val_epoch_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for batch in val_loader:\n",
    "            inputs, dummies = batch\n",
    "            inputs = inputs.float().to(device)\n",
    "            dummies = dummies.float().to(device)\n",
    "\n",
    "            outputs_class = model(inputs)\n",
    "\n",
    "            outputs_reshaped = outputs_class.view(-1, params['num_classes'])\n",
    "            dummies_reshaped = dummies.view(-1, params['num_classes'])\n",
    "            val_loss = criterion(outputs_reshaped, dummies_reshaped.argmax(dim=1))\n",
    "\n",
    "            val_epoch_loss += val_loss.item()\n",
    "    \n",
    "    #scheduler.step(val_epoch_loss)\n",
    "\n",
    "    average_val_loss = val_epoch_loss / len(val_loader)\n",
    "    val_losses.append(average_val_loss)\n",
    "    print(f'Epoch {epoch+1}/{num_epochs}, Validation Loss: {average_val_loss}')\n",
    "\n",
    "    # Add your early stopping logic here if needed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24371"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(p.numel() for p in model.parameters() if p.requires_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "pLcEa2SD3yY-"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot the training and validation loss curve\n",
    "plt.plot(train_losses, label='Training Loss')\n",
    "plt.plot(val_losses, label='Validation Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training and Validation Loss Curve')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "r9k0p5-46Pt1"
   },
   "outputs": [],
   "source": [
    "from tensorflow_addons.layers import TransformerEncoder, TransformerDecoder\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "\n",
    "# Next, we build a deep network.\n",
    "# The first layer is a TransformerEncoder layer followed by a TransformerDecoder layer.\n",
    "# Dropout is also applied after each layer to control overfitting.\n",
    "# Final layer is a Dense output layer with single unit and sigmoid activation since this is a binary classification problem.\n",
    "# build the network\n",
    "\n",
    "# Initializes a sequential model, which allows you to build a model layer by layer.\n",
    "model = Sequential()\n",
    "\n",
    "# Adds a TransformerEncoder layer to the model.\n",
    "model.add(TransformerEncoder(\n",
    "    head_size=64,\n",
    "    num_heads=8,\n",
    "    ff_dim=256,\n",
    "    dropout=0.2,\n",
    "    input_shape=(sequence_length, nb_features)\n",
    "))\n",
    "\n",
    "# Adds a TransformerDecoder layer to the model.\n",
    "model.add(TransformerDecoder(\n",
    "    head_size=64\n",
    "    num_heads=8,\n",
    "    ff_dim=256,\n",
    "    dropout=0.2\n",
    "))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "# Adds a dense (fully connected) layer to the model with a softmax activation function. This layer produces the output classes.\n",
    "model.add(Dense(units=nb_out, activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "print(model.summary())\n",
    "\n",
    "# fit the network\n",
    "history = model.fit(seq_array, dummy_label_array, epochs=100, batch_size=200, validation_split=0.05, verbose=2,\n",
    "          callbacks = [keras.callbacks.EarlyStopping(monitor='val_loss', min_delta=0, patience=10, verbose=0, mode='min'),\n",
    "                       keras.callbacks.ModelCheckpoint(model_path,monitor='val_loss', save_best_only=True, mode='min', verbose=0)]\n",
    "          )\n",
    "\n",
    "# list all data in history\n",
    "print(history.history.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4sWk2GlE6Pt2"
   },
   "source": [
    "# Every time I retrain the algorithm I get different training results, i.e., also different evaluation of the decisions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pWyZJ2mP-1pB"
   },
   "source": [
    "## Model Evaluation on Validation set created during the training (i.e., validation_split=0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FpVYSzXkmk5l"
   },
   "outputs": [],
   "source": [
    "# summarize history for Accuracy\n",
    "fig_acc = plt.figure(figsize=(10, 10))\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()\n",
    "# fig_acc.savefig(\"model_accuracy.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-u2aW0bj6Pt3"
   },
   "outputs": [],
   "source": [
    "# summarize history for Loss\n",
    "fig_acc = plt.figure(figsize=(10, 10))\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()\n",
    "# fig_acc.savefig(\"model_loss.png\")\n",
    "\n",
    "# training metrics\n",
    "scores = model.evaluate(seq_array, dummy_label_array, verbose=1, batch_size=200)\n",
    "print('Accurracy: {}'.format(scores[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iK6St5XcVyd9"
   },
   "source": [
    "`y_pred = (model.predict(seq_array) > 0.5).astype(\"int32\"):` Predicts the abels for the input sequences using the trained model. The predictions are hresholded at 0.5, meaning that any output probability greater than 0.5 is considered as class 1, otherwise class 0. The predictions are then converted to integers (0 or 1).<br>\n",
    "\n",
    "`y_true = dummy_label_array:` Sets the true labels from the dummy label array, which represents the actual labels of the data.\n",
    "then print the **confusion_matrix**\n",
    "\n",
    "`cm = confusion_matrix(y_true.argmax(axis=1), y_pred.argmax(axis=1)):` Computes the confusion matrix using the true labels (`y_true`) and the predicted labels `(y_pred). argmax(axis=1)` is used to convert one-hot encoded labels back to their original integer form before computing the confusion matrix.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KRwaYKfV6Pt4"
   },
   "outputs": [],
   "source": [
    "# make predictions and compute confusion matrix\n",
    "# y_pred = model.predict_classes(seq_array,verbose=1, batch_size=200)\n",
    "y_pred = (model.predict(seq_array) > 0.5).astype(\"int32\") # this way (>0.5) the outcome goes from a probability to 0,1\n",
    "y_true = dummy_label_array\n",
    "\n",
    "# test_set = pd.DataFrame(y_pred)\n",
    "# # test_set.to_csv('binary_submit_train.csv', index = None)\n",
    "\n",
    "print('Confusion matrix\\n- x-axis is true labels.\\n- y-axis is predicted labels')\n",
    "cm = confusion_matrix(y_true.argmax(axis=1), y_pred.argmax(axis=1))\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oxvEuR4S-6VI"
   },
   "source": [
    "## Second PdM policy evaluation on the test set.\n",
    "\n",
    "For each test set, I need to give the on-line sensor data as input to the trained Transformer.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "k_GqqVKV6Pt4"
   },
   "outputs": [],
   "source": [
    "if os.path.isfile(model_path):\n",
    "    estimator = load_model(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vloF6HXQ6Pt4"
   },
   "outputs": [],
   "source": [
    "# Assumptions for the costs, taken by the 2019 RESS paper\n",
    "C_p    = 100\n",
    "C_c    = 1000\n",
    "C_unav = 10\n",
    "C_inv  = 1\n",
    "DT     = 10  # Decisions can be taken every DT=10\n",
    "L      = 20  # lead time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PZ-vs1-x6Pt5"
   },
   "outputs": [],
   "source": [
    "array_decisions = np.arange(0,400,10) # decisions can only be made every DT = 10 cycles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5KP5yjWw6Pt5"
   },
   "outputs": [],
   "source": [
    "# estimator.predict(seq_array_validation_k).reshape(3) returns a vector with 3 elements\n",
    "# [Pr(RUL>w1), Pr(w0<RUL<=w1), Pr(RUL<=w0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PqIzk2b96Pt5"
   },
   "outputs": [],
   "source": [
    "test_df['cycle_norm'] = test_df['cycle']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tAF7B0eOY1BN"
   },
   "outputs": [],
   "source": [
    "test_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MBklUcnv6Pt5"
   },
   "source": [
    "## Second PdM policy evaluation on a the whole validation data set (ids 81 to 100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vfyabzdL6Pt_"
   },
   "outputs": [],
   "source": [
    "costs_rep_array   = np.zeros(20) # An array to store costs related to replacements.\n",
    "\n",
    "costs_delay_array = np.zeros(20) # An array to store costs related to delays.\n",
    "costs_stock_array = np.zeros(20) # An array to store costs related to stock.\n",
    "\n",
    "t_LC_array        = np.zeros(20) # An array to store lead time.\n",
    "t_order_array     = np.zeros(20) # An array to store order time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JsWT1ebGbOdz"
   },
   "source": [
    "> 1. Initializes a counter variable to 0.\n",
    "> 2. Iterates over unique IDs in the `test_df` DataFrame.\n",
    "> 3. For each ID:\n",
    ">> * Sets flags for preventive replacement and ordering to False.<br>\n",
    ">> * Iterates over cycles within the range of the DataFrame.<br>\n",
    ">> * Checks if the current cycle is in the `array_decisions`.<br>\n",
    ">> * If it is, preprocesses the validation data for the LSTM model.<br>\n",
    ">> * Predicts the probability of RUL being smaller than w1 and DT (decision time) using the trained model.<br>\n",
    ">> * Evaluates decision heuristics:\n",
    ">>> * If no order has been placed yet and the cost of preventive replacement is less than or equal to the cost of waiting until `w1`, orders the component and sets the order time.<br>\n",
    ">>> * If the cost of preventive replacement is less than or equal to the cost of waiting until `DT`, performs preventive replacement, calculates related costs, and breaks the loop.<br>\n",
    ">> If preventive replacement is not performed:\n",
    ">>> * Sets the component failure time to the last cycle in the ID's data.<br>\n",
    ">>> * Sets replacement costs to `C_c`.<br>\n",
    ">>> * Calculates delay costs based on whether an order has been placed.<br>\n",
    ">> * Prints diagnostic information for each iteration.\n",
    ">> * Increments the counter.\n",
    "\n",
    "\n",
    "This code essentially simulates a decision-making process for component maintenance based on predictive models and cost considerations.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jG8Lip5w6Pt_",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "counter = 0\n",
    "for id in test_df['id'].unique():\n",
    "    print('ID:', id)\n",
    "    preventive_replacement = False\n",
    "    order                  = False\n",
    "\n",
    "    for cycle in range(test_df[test_df['id']==id].shape[0]-sequence_length+1):\n",
    "\n",
    "        if cycle in array_decisions:\n",
    "\n",
    "            norm_validation_df = pd.DataFrame(min_max_scaler.transform(test_df[test_df['id']==id][cols_normalize][:sequence_length+cycle]),\n",
    "                 columns=cols_normalize,\n",
    "                 index=test_df[test_df['id']==id][:sequence_length+cycle].index)\n",
    "\n",
    "            join_df = test_df[test_df['id']==id][:sequence_length+cycle][test_df[test_df['id']==id][:sequence_length+cycle].columns.difference(cols_normalize)].join(norm_validation_df)\n",
    "            validation_df_eval_online = join_df.reindex(columns = test_df[test_df['id']==id][cycle:sequence_length+cycle].columns)\n",
    "\n",
    "            seq_array_validation_k = validation_df_eval_online[sequence_cols].values[cycle:sequence_length+cycle]\n",
    "            seq_array_validation_k = np.asarray(seq_array_validation_k).astype(np.float32).reshape(1,sequence_length, nb_features)\n",
    "            prob_RUL_smaller_DT    = estimator.predict(seq_array_validation_k).reshape(3)[2]\n",
    "            prob_RUL_smaller_w1    = estimator.predict(seq_array_validation_k).reshape(3)[1]\n",
    "\n",
    "            print('prob_RUL_smaller_w1:', prob_RUL_smaller_w1)\n",
    "            print('prob_RUL_smaller_DT:', prob_RUL_smaller_DT)\n",
    "\n",
    "\n",
    "            # evaluate decision heuristics\n",
    "            if order == False:\n",
    "                if C_p <= prob_RUL_smaller_w1*C_c:\n",
    "                    print('prob_RUL_smaller_w1:', prob_RUL_smaller_w1)\n",
    "                    print('prob_RUL_smaller_DT:', prob_RUL_smaller_DT)\n",
    "                    t_order_array[counter] = sequence_length+cycle\n",
    "                    order = True\n",
    "                    print('component ordering at cycle:', t_order_array[counter])\n",
    "\n",
    "            if C_p <= prob_RUL_smaller_DT*C_c:\n",
    "                print('prob_RUL_smaller_DT:', prob_RUL_smaller_DT)\n",
    "\n",
    "                t_LC_array[counter] = sequence_length+cycle\n",
    "                costs_rep_array[counter] = C_p\n",
    "                print('preventive replacement informed at cycle:', t_LC_array[counter])\n",
    "                # print('component lifecycle:', t_LC)\n",
    "                preventive_replacement = True\n",
    "                costs_delay_array[counter] = max(t_order_array[counter]+L-t_LC_array[counter], 0) * C_unav\n",
    "\n",
    "                costs_stock_array[counter]  = max(t_LC_array[counter] -(t_order_array[counter]+L), 0)*C_inv\n",
    "                # print('delay time', max(t_order+L-t_LC, 0))\n",
    "                # print('cost_delay_id:',cost_delay_id)\n",
    "                # print('cost of stock:', cost_stock_id)\n",
    "                break\n",
    "\n",
    "    if preventive_replacement == False:\n",
    "        t_LC_array[counter] = test_df[test_df['id']==id]['cycle'].iloc[-1]\n",
    "        print('Component failure at t:', t_LC_array[counter])\n",
    "        costs_rep_array[counter] = C_c\n",
    "\n",
    "        if order == False:\n",
    "            costs_delay_array[counter] = L * C_unav\n",
    "        else:\n",
    "            costs_delay_array[counter] = max(t_order_array[counter]+L-t_LC_array[counter], 0) * C_unav\n",
    "            costs_stock_array[counter] = max(t_LC_array[counter] -(t_order_array[counter]+L), 0)*C_inv\n",
    "\n",
    "    print('True failure:', test_df[test_df['id']==id]['cycle'].iloc[-1])\n",
    "    print('-----------------------------------------')\n",
    "    counter+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "onea6sLe6PuA"
   },
   "outputs": [],
   "source": [
    "costs_rep_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FAvJN15m6PuA"
   },
   "outputs": [],
   "source": [
    "costs_delay_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-Mmc0YIA6PuA"
   },
   "outputs": [],
   "source": [
    "costs_stock_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IkJNf5d26PuB"
   },
   "outputs": [],
   "source": [
    "costs_tot = costs_rep_array+costs_delay_array+costs_stock_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Lp4AF1KW6PuB"
   },
   "outputs": [],
   "source": [
    "costs_tot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fzXo4Qlw6PuB"
   },
   "outputs": [],
   "source": [
    "t_LC_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QCNUa2J36PuB"
   },
   "outputs": [],
   "source": [
    "t_order_array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "S6g7k8Yrftya"
   },
   "source": [
    "### This code calculates the expected cost per unit time using the LSTM model. It computes the mean of the total costs divided by the mean of the time to component failure (t_LC_array). This metric gives an estimate of the average cost incurred per unit time in the system, considering both maintenance and operational costs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "P3_N4kNM6PuC"
   },
   "outputs": [],
   "source": [
    "expected_cost_LSTM = np.mean(costs_tot) / np.mean(t_LC_array)\n",
    "expected_cost_LSTM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HQgoTz57gC_P"
   },
   "source": [
    "This code segment calculates the expected cost per unit time assuming perfect prognostics.\n",
    "`1. Perfect Prognostics Calculation:`\n",
    "> * It initializes an array `t_LC_perfect_array` to store the time of component failure for each unit in the validation dataset. This is calculated by dividing the last observed cycle number by the decision interval DT and then flooring the result to get the last decision cycle before failure.\n",
    "> * The loop iterates over each unique ID in the validation dataset, calculates the time of component failure for each unit, and stores it in\n",
    "`t_LC_perfect_array`.<br>\n",
    "> * `math.floor()` is used to round down the result to the nearest multiple of `DT`.\n",
    "> * Finally, the loop increments the counter for each unit.<br>\n",
    "\n",
    "`2. Cost Calculation:`\n",
    "> * `costs_perfect_array` is initialized with a value of `C_p`, representing the cost of preventive replacements. In a perfect scenario, only preventive replacements are made.\n",
    "> * This array holds the same cost value for each unit in the validation dataset.\n",
    "\n",
    "`3. Expected Cost Calculation:`\n",
    "> * `expected_cost_perfect` is calculated by taking the mean of `costs_perfect_array` and dividing it by the mean of `t_LC_perfect_array`.\n",
    "> * This calculation provides an estimate of the average cost per unit time assuming perfect prognostics, where components are replaced preventively at regular intervals.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IOD6NDfH6PuC"
   },
   "outputs": [],
   "source": [
    "# Perfect prognostics\n",
    "import math\n",
    "t_LC_perfect_array  = np.zeros(20)\n",
    "counter=0\n",
    "for id in validation_df['id'].unique():\n",
    "    t_LC_perfect_array[counter] = math.floor(validation_df[validation_df['id']==id]['cycle'].iloc[-1] /DT) * DT\n",
    "    counter+=1\n",
    "\n",
    "costs_perfect_array = np.ones(20)*C_p # a perfect policy will only lead to preventive replacements\n",
    "\n",
    "expected_cost_perfect = np.mean(costs_perfect_array)/np.mean(t_LC_perfect_array)\n",
    "expected_cost_perfect\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "H-vK-DBi6PuC"
   },
   "outputs": [],
   "source": [
    "t_LC_perfect_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZY7_LJce6PuC"
   },
   "outputs": [],
   "source": [
    "# evaluation of the metric defined in the paper\n",
    "M = (expected_cost_LSTM - expected_cost_perfect) / expected_cost_perfect\n",
    "M # it obtains a very small value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KofjvavY6PuD"
   },
   "outputs": [],
   "source": [
    "M*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "P42Nu-Rg6PuE"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "name": "",
   "version": ""
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
